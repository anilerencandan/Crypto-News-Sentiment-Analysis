{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6866b372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7395 başlık ve içerik başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_page_content(url):\n",
    "    \"\"\"Verilen URL'den sayfa içeriğini alır.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "def extract_article_links(soup):\n",
    "    \"\"\"Sayfa içeriğinden makale başlıklarını ve bağlantılarını çeker.\"\"\"\n",
    "    articles = soup.find_all('h2', class_='entry-title')\n",
    "    links = []\n",
    "    titles = []\n",
    "    \n",
    "    for article in articles:\n",
    "        title = article.get_text(strip=True)\n",
    "        link = article.find_parent('a')['href']\n",
    "        titles.append(title)\n",
    "        links.append(link)\n",
    "        \n",
    "    return titles, links\n",
    "\n",
    "def extract_article_content(link):\n",
    "    \"\"\"Verilen makale bağlantısından içeriği çeker.\"\"\"\n",
    "    article_soup = fetch_page_content(link)\n",
    "    content_div = article_soup.find('div', class_='entry-content')\n",
    "    \n",
    "    if content_div:\n",
    "        # Paylaşım butonlarını içeren div'i kaldır\n",
    "        share_buttons = content_div.find('div', class_='share_buttons')\n",
    "        if share_buttons:\n",
    "            share_buttons.extract()\n",
    "        \n",
    "        # Uyarı metnini içeren div'i kaldır\n",
    "        warning_block = content_div.find('div', class_='ytd-block')\n",
    "        if warning_block:\n",
    "            warning_block.extract()\n",
    "\n",
    "        # Kalan içeriği al\n",
    "        return content_div.get_text(strip=True)\n",
    "    return \"\"\n",
    "\n",
    "def scrape_coinkolik(total_pages):\n",
    "    \"\"\"Tüm sayfalardan haber başlıklarını ve içeriklerini çeker.\"\"\"\n",
    "    all_titles = []\n",
    "    all_contents = []\n",
    "    \n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = f'https://www.coinkolik.com/kripto-para-haberleri/page/{page}/'\n",
    "        soup = fetch_page_content(url)\n",
    "        titles, links = extract_article_links(soup)\n",
    "\n",
    "        all_titles.extend(titles)\n",
    "\n",
    "        for link in links:\n",
    "            content = extract_article_content(link)\n",
    "            all_contents.append(content)\n",
    "\n",
    "    return all_titles, all_contents\n",
    "\n",
    "def save_to_csv(titles, contents, filename):\n",
    "    \"\"\"Başlıkları ve içerikleri CSV dosyasına kaydeder.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'Başlık': titles,\n",
    "        'İçerik': contents\n",
    "    })\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"{len(titles)} başlık ve içerik başarıyla kaydedildi.\")\n",
    "\n",
    "# Ana işlem\n",
    "if __name__ == \"__main__\":\n",
    "    total_pages = 925\n",
    "    titles, contents = scrape_coinkolik(total_pages)\n",
    "    save_to_csv(titles, contents, 'coincolik_scraping.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6449d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8dc52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
